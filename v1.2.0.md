# Harvester v1.2.0 Release Note

<!--- TO-DO -->
This release follows Harvester v1.2.0, the documentation is available at https://docs.harvesterhci.io/v1.2.

# Important information about Rancher support

<!--- TO-DO -->

# Downloads

<!--- TO-DO -->

## ISO

<!--- TO-DO -->
:cd: [harvester-v1.1.2-amd64.iso](https://releases.rancher.com/harvester/v1.1.2/harvester-v1.1.2-amd64.iso)

## Additional Artifacts

<!--- TO-DO -->

# Install

<!--- TO-DO -->
Harvester can be installed with the [ISO](https://docs.harvesterhci.io/v1.1/install/iso-install/) image or via [PXE](https://docs.harvesterhci.io/v1.1/install/pxe-boot-install/) boot.

# Highlights

- The system footprint of Harvester is reduced, better fitting Edge use cases. See [#3262](https://github.com/harvester/harvester/issues/3262).
- When mirgrating VMs in Harvester, the resource limit of `ResourceQuota` is increased based on the the specifications of the target VM before migration. When the migration is complete, the resource limit of `ResourceQuota` is decreased or restored to it's previous value. See [#3124](https://github.com/harvester/harvester/issues/3124).
- Harvester supports adding an emulated Trusted Platform Module (TPM) to a VM. TPM is a cryptoprocessor that secures hardware using cryptographic keys and is a hard requirement of Windows 11. See [#2910](https://github.com/harvester/harvester/issues/2910).
- Harvester supports passing through SR-IOV capable network virtual functions (VFs) to workload VMs. See [#2763](https://github.com/harvester/harvester/issues/2763).
- When VMs are being migrated, pods are drained from the node during maintence mode. See [#2723](https://github.com/harvester/harvester/issues/2723).
- Pod limit per node increased to 200. See [#2707](https://github.com/harvester/harvester/issues/2707).
- Harvester node driver supports multiple NICs and multiple disks. See [#2426](https://github.com/harvester/harvester/issues/2426).
- Harvester supports installing a Container Storage Interface (CSI) in your Harvester cluster to support and use external storage as the VM's non-system data partition. See [#2405](https://github.com/harvester/harvester/issues/2405).
- Enable `harvester-seeder` to configure `Out-of-Band Access` for a node and map the corresponding underlying hardware to a node. See [#2318](https://github.com/harvester/harvester/issues/2318).
- Harvester supports creating a VM template with data from an existing VM, including root and data disks. See [#571](https://github.com/harvester/harvester/issues/571).
- New installation mode supports installing Harvester to a machine without configuring the node. See [#2198](https://github.com/harvester/harvester/issues/2198).

<!--- TO-DO -->
- [#2679](https://github.com/harvester/harvester/issues/2679)
- [#2134](https://github.com/harvester/harvester/issues/2134)
- [#571](https://github.com/harvester/harvester/issues/571)

# Upgrade

<!--- TO-DO -->
[Upgrade from v1.1.0/v1.1.1 to v1.1.2](https://docs.harvesterhci.io/v1.1/upgrade/automatic/)

# Major Bug Fixes

- **Booting in EFI mode** checkbox is not working correctly with Terraform Harvester Provider. See [#4145](https://github.com/harvester/harvester/issues/4145).
- When you try to upgrade from Harvester v1.1.2 to v1.2.0, the upgrade is stuck on `Waiting for RKE2 to be upgraded`. `fleet-agent` was scaled down but failed to scale up. See [#4119](https://github.com/harvester/harvester/issues/4119).
- When you try to upgrade from Harvester v1.1.2 to v1.2.0, the upgrade is stuck on the `post-drain` job, and the VM is unresponsive. See [#4095](https://github.com/harvester/harvester/issues/4095).
- **Projects/Namespaces** page is not available. See [#4094](https://github.com/harvester/harvester/issues/4094).
- When accessing an imported Harvester in Rancher, Grafana metrics don't display. See [#4087](https://github.com/harvester/harvester/issues/4087).
- A VM needs at least 10 minutes to recover after a host failure automatically. See [#4049](https://github.com/harvester/harvester/issues/4049).
- The `harvester_config` of terraform-provider-rancher2 v1.25.0 and v3.0.0 are incompatible. See [#3997](https://github.com/harvester/harvester/issues/3997).
- When creating an IP Pool, the **Project** drop-down list is missing when the MCM (rancher-manager-support) setting is enabled. See [#3984](https://github.com/harvester/harvester/issues/3984).
- When you upgrade from Harvester v1.1.2 to v1.2.0 and the **pcidevices-controller** is **Enabled**, no PCI Devices are displayed. See [#3957](https://github.com/harvester/harvester/issues/3957).
- When you upgrade from Harvester v1.1.2 to v1.2.0, you are unable to restore an existing VM snapshot. See [#3943](https://github.com/harvester/harvester/issues/3943).
- When viewing Harvester cluster from **Virtualization Management** page in Rancher, you cannot see a newly created volume from the **Volumes** page. See [#3873](https://github.com/harvester/harvester/issues/3873).
- When you upgrade from Harvester v1.1.2 to v1.2.0, a change in Rancher causes upgrading RKE2 to fail because the `local-rke-state` secret is the wrong type. See [#3858](https://github.com/harvester/harvester/issues/3858).
- When editing a Host configuration, you cannot view or edit Disk tags. See [#3849](https://github.com/harvester/harvester/issues/3849).
- When creating an RKE2 cluster in Harvester in Rancher, the cluster's volumes and networks differ from the final configuration. See [#3786](https://github.com/harvester/harvester/issues/3786).
- When a node has a memory size of more than 1000 GB, the node resources on the **Host** page are not displayed correctly. See [#3607](https://github.com/harvester/harvester/issues/3607).
- When creating **Output** or **Cluster Output**, the output provider **OpenSearch** is missing. See [#3589](https://github.com/harvester/harvester/issues/3589).
- VM with hotplug volume gives IO error after deleing hotplug volume pods twice. See [#3586](https://github.com/harvester/harvester/issues/3586).
- The setting controller does not reprocess the value when there is an error. See [#3519](https://github.com/harvester/harvester/issues/3519).
- Fixed `invalid havester-csi-ccm-versions` setting. See [#3404](https://github.com/harvester/harvester/issues/3404).
- Can not control `qemu-guest-agent` `cloud-init` when creating RKE2 cluster. See [#3392](https://github.com/harvester/harvester/issues/3392).
- Cluster Members cannot see Cluster Networks to choose from when creating a VM Network. See [#3300](https://github.com/harvester/harvester/issues/3300).
- Volume created by the Harvester CSI driver gets deleted after reprovisioning RKE2 nodes. See [#3272](https://github.com/harvester/harvester/issues/3272).
- During an upgrade, multiple nodes are cordoned off, causing the upgrade to be stuck waiting for volumes to become healthy. See [#3216](https://github.com/harvester/harvester/issues/3216).
- Time sync config and time sync monitoring missing. See [#3133](https://github.com/harvester/harvester/issues/3133).
- `server_url` with `https://` but without the port `:443` causes node join to fail. See [#2737](https://github.com/harvester/harvester/issues/2737).
- No resource limits set for the Kubevirt pods in `harvester-system` namespace. See [#2729](https://github.com/harvester/harvester/issues/2729).
- An upgrade is stuck with a node in "Pre-drained" state since the node's volume has too many system snapshots. See [#2640](https://github.com/harvester/harvester/issues/2640).

<!--- TO-DO -->
- The /etc/rancher/rke2/registries.yaml file become empty after upgrading the embedded Rancher to 2.7.5. [#4516](https://github.com/harvester/harvester/issues/4156)
- Upgrade is stuck in "Pre-drained" state (Volume has too many system snapshots). [#2640](https://github.com/harvester/harvester/issues/2640)

# Others
<!--- TO-DO -->

# Known Issues
<!--- TO-DO -->
[Open Issues w/ require/release-note label](https://github.com/harvester/harvester/issues?q=is%3Aissue+label%3Arequire%2Frelease-note+is%3Aopen)
- When multiple rke2 clusters exist in the same namespace, an `re-sync topology error: nodes not found in cloud-provider` occurs where the nodes cannot be found in the cloud-provider controller. [#4459](https://github.com/harvester/harvester/issues/4459)
- Fail to scale down RKE2 Harvester node driver cluste. [#4358](https://github.com/harvester/harvester/issues/4358)
- Failed to upgrade 4 nodes from v1.1.2 to v1.2.0-rc4, stuck in post-draining on the third node. [#4285](https://github.com/harvester/harvester/issues/4285)
- Failed to pass guest cluster name into Harvester cloud provider. [#4232](https://github.com/harvester/harvester/issues/4232)
- Unable to access Node IP addresses over HTTPS on VM router in Harvester cluster v1.1.1. [#3960](https://github.com/harvester/harvester/issues/3960)
- Upgrade stuck on Waiting for CAPI cluster fleet-local/local to be provisioned. [#3863](https://github.com/harvester/harvester/issues/3863)
- Unable to select Harvester Cloud Provider in Rancher v2.7.2-rc8. [#3750](https://github.com/harvester/harvester/issues/3750)
- Harvester v1.1.1 upgrade may stuck in another operation (install/upgrade/rollback) by fleet. [#3675](https://github.com/harvester/harvester/issues/3675)
- Upgrade from v1.0.3 to v1.1.1-rc1, Harvester cluster stuck in pre-draining the second node. [#3164](https://github.com/harvester/harvester/issues/3164)
- Upgrade stop at upgrading node3 stage, stuck in Pre-drained state. [#3021](https://github.com/harvester/harvester/issues/3021)
- Upgrade stuck in upgrading first node: Job was active longer than specified deadline. [#2894](https://github.com/harvester/harvester/issues/2894)

# Dependency Component Versions
<!--- TO-DO -->
| Component | Version |
| ------ | ---------|
| Longhorn | [v1.3.2](https://github.com/longhorn/longhorn/releases/tag/v1.3.2) |
| KubeVirt | [v0.54.0](https://github.com/kubevirt/kubevirt/releases/tag/v0.54.0) |
| Rancher | [v2.6.10](https://github.com/rancher/rancher/releases/tag/v2.6.10) |
| RKE2 | [v1.24.10+rke2r1](https://github.com/rancher/rke2/releases/tag/v1.24.10%2Brke2r1) |

# Contributors
<!--- TO-DO -->
